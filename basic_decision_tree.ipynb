{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1fe839b8b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from models import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m data = np.array([[-4, -4, 0], [-3, -3, 0], [-2, -2, 0], [-1, -1, 0], [1, 1, 0], [2, 2, 0], [3, 3, 0],\n\u001b[0m\u001b[1;32m      5\u001b[0m                 [1, -1, 1], [2, -2, 1], [3, -3, 3], [-1, 1, 1], [-2, 2, 1], [-3, 3, 1]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# classification\n",
    "# from models import *\n",
    "data = np.array([[-4, -4, 0], [-3, -3, 0], [-2, -2, 0], [-1, -1, 0], [1, 1, 0], [2, 2, 0], [3, 3, 0],\n",
    "                [1, -1, 1], [2, -2, 1], [3, -3, 3], [-1, 1, 1], [-2, 2, 1], [-3, 3, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number train examples: 24000 \n",
      "Number validation examples: 3000 \n",
      "Number of test examples: 3000 \n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import pandas as pd\n",
    "dataset = load_dataset('taiwan_credit_risk', train_prop=0.8, valid_prop=0.1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dataset.X_train)\n",
    "df['y'] = dataset.y_train\n",
    "\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('datasets/ames_housing/ames_housing_training.csv', index_col=0)\n",
    "df2 = pd.DataFrame(dataset2)\n",
    "\n",
    "df2=df2.select_dtypes([np.number]).dropna()\n",
    "data2_train = df2.to_numpy()[:(int)(0.9*len(df2))]\n",
    "data2_val = df2.to_numpy()[(int)(0.9*len(df2)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    dataset = pd.read_csv(path, index_col=0)\n",
    "    df = pd.DataFrame(dataset)\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    df= df.select_dtypes([np.number]).dropna()\n",
    "    data_train = df.to_numpy()[:(int)(0.9*len(df))]\n",
    "    data_val = df.to_numpy()[(int)(0.9*len(df)):]\n",
    "    return df, data_train, data_val\n",
    "\n",
    "def k_fold(path):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    dataset = pd.read_csv(path, index_col=0)\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df=df.select_dtypes([np.number]).dropna()\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        b_train = df.to_numpy()[train_index]\n",
    "        b_val = df.to_numpy()[test_index]\n",
    "        l1.append(b_train)\n",
    "        l2.append(b_val)\n",
    "    return df, l1, l2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike, b_train, b_val = k_fold('datasets/Bike-Sharing-Dataset/day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 0.000e+00, 1.000e+00, ..., 3.310e+02, 6.540e+02,\n",
       "        9.850e+02],\n",
       "       [1.000e+00, 0.000e+00, 1.000e+00, ..., 1.310e+02, 6.700e+02,\n",
       "        8.010e+02],\n",
       "       [1.000e+00, 0.000e+00, 1.000e+00, ..., 1.200e+02, 1.229e+03,\n",
       "        1.349e+03],\n",
       "       ...,\n",
       "       [1.000e+00, 1.000e+00, 1.200e+01, ..., 1.590e+02, 1.182e+03,\n",
       "        1.341e+03],\n",
       "       [1.000e+00, 1.000e+00, 1.200e+01, ..., 3.640e+02, 1.432e+03,\n",
       "        1.796e+03],\n",
       "       [1.000e+00, 1.000e+00, 1.200e+01, ..., 4.390e+02, 2.290e+03,\n",
       "        2.729e+03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity_regression(data, threshold):\n",
    "    return len(data) < threshold\n",
    "\n",
    "def calculate_mse(data_below, data_above):\n",
    "    # Getting the means \n",
    "    below_mean = np.mean(data_below[:,-1])\n",
    "    above_mean = np.mean(data_above[:,-1]) \n",
    "    # Getting the left and right residuals \n",
    "    res_below = data_below[:,-1] - below_mean \n",
    "    res_above = data_above[:,-1] - above_mean\n",
    "    # Concatenating the residuals \n",
    "    r = np.concatenate((res_below, res_above), axis=None)\n",
    "\n",
    "    # Calculating the mse \n",
    "    n = len(r)\n",
    "    r = r ** 2\n",
    "    r = np.sum(r)\n",
    "    mse_split = r / n\n",
    "    return mse_split\n",
    "\n",
    "def calc_mse_whole(data):\n",
    "    r = data[:,-1]-np.mean(data[:,-1])\n",
    "    n = len(r)\n",
    "    r = r ** 2\n",
    "    r = np.sum(r)\n",
    "    mse = r / n\n",
    "    return mse\n",
    "\n",
    "def get_potential_splits(data, n_columns, isForest=False):\n",
    "#     print(f\"finding splits for {data.shape}\")\n",
    "    potential_splits = {}\n",
    "    if isForest:\n",
    "        features = list()\n",
    "        while len(features) < n_features:\n",
    "            index = randrange(len(data.shape[1])-1)\n",
    "            if index not in features:\n",
    "                features.append(index)\n",
    "    else:\n",
    "        features = [i for i in range(n_columns-1)]\n",
    "    for column_index in features:\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        for index in range(1, len(unique_values)):\n",
    "            previous_value = unique_values[index - 1]\n",
    "            current_value = unique_values[index]\n",
    "            potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "            potential_splits[column_index].append(potential_split)\n",
    "\n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def determine_best_split(data, potential_splits):\n",
    "#     print(f\"Determining best split for {data.shape}\")\n",
    "    overall_mse = calc_mse_whole(data)\n",
    "    for column_index in potential_splits:\n",
    "#         print(f\"column index: {column_index}\")\n",
    "        time_split = 0\n",
    "        for value in potential_splits[column_index]:\n",
    "            \n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_mse = calculate_mse(data_below, data_above)\n",
    "            if current_overall_mse < overall_mse:\n",
    "                overall_mse = current_overall_mse\n",
    "#                 print(f\"overall mse: {overall_mse}\")\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "def regression_tree(x_train, y_train, threshold):\n",
    "    data = np.concatenate((x_train, y_train), axis=1)\n",
    "    regression_tree_helper(data, threshold)\n",
    "\n",
    "\n",
    "def regression_tree_helper(data, threshold):\n",
    "\n",
    "#     print(data.shape)\n",
    "    if len(data) <= threshold:\n",
    "        return data[:, -1]\n",
    "    else:\n",
    "        potential_splits = get_potential_splits(data, data.shape[1])\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "\n",
    "        # instantiate sub-tree\n",
    "        question = \"{} <= {}\".format(split_column, split_value)\n",
    "        sub_tree = {question: []}\n",
    "\n",
    "        # find answers (recursion)\n",
    "        yes_answer = regression_tree_helper(data_below, threshold)\n",
    "        no_answer = regression_tree_helper(data_above, threshold)\n",
    "\n",
    "        sub_tree[question].append(yes_answer)\n",
    "        sub_tree[question].append(no_answer)\n",
    "\n",
    "        return sub_tree\n",
    "\n",
    "\n",
    "def classify_example(example, decision_tree, q):\n",
    "    question = list(decision_tree.keys())[0] # decision_tree.keys() returns a dictionary\n",
    "    feature_name, comparison_operator, value = question.split() # question is of form '0' <= 0.5'\n",
    "\n",
    "    # ask question\n",
    "    if example[int(feature_name)] <= float(value):\n",
    "        answer = decision_tree[question][0]\n",
    "    else:\n",
    "        answer = decision_tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return np.quantile(answer, q)\n",
    "\n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree, q)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pred(main_tree, val):\n",
    "    pred = []\n",
    "    for x in val:\n",
    "#         print(f\"predict: {classify_example(x[:-1], main_tree, 0.95)}\")\n",
    "#         print(f\"predict: {classify_example(x[:-1], main_tree, 0.05)}\")\n",
    "#         print(f\"predict: {classify_example(x[:-1], main_tree, 0.5)}\")\n",
    "#         print(f\"real: {x[-1]}\")\n",
    "        pred.append(classify_example(x[:-1], main_tree, 0.5))\n",
    "    return pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse_val(pred, y):\n",
    "    r = np.sum((pred-y)**2)\n",
    "    n = len(y)\n",
    "    mse = r / n\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae_val(pred, y):\n",
    "    r = np.sum(abs(pred-y))\n",
    "    n = len(y)\n",
    "    mae = r / n\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(val, main_tree):\n",
    "    accuracy = 0\n",
    "    for x in val:\n",
    "        top = classify_example(x[:-1], main_tree, 0.975)\n",
    "        bottom = classify_example(x[:-1], main_tree, 0.025)\n",
    "        if x[-1] <= top and x[-1] >= bottom:\n",
    "            accuracy += 1\n",
    "\n",
    "    percent = accuracy / len(val)\n",
    "    return percent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qt =  80217.26331967213\n",
      "t =  62389.688524590165\n",
      "accucracy =  0.4057377049180328\n",
      "qt =  49109.33196721312\n",
      "t =  52098.516393442624\n",
      "accucracy =  0.5040983606557377\n",
      "qt =  56272.28703703704\n",
      "t =  48572.33744855967\n",
      "accucracy =  0.49382716049382713\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#baseline comparison\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "cmp = 0\n",
    "for i in range(len(b_train)):\n",
    "    main_tree = regression_tree_helper(b_train[i], 10)\n",
    "    p = find_pred(main_tree, b_val[i])\n",
    "    regressor = DecisionTreeRegressor(random_state=0)\n",
    "    regressor.fit(b_train[i][:,:-1], b_train[i][:,-1])\n",
    "    p2 = [x for x in regressor.predict(b_val[i][:,:-1])]\n",
    "    qt = calc_mse_val(p, b_val[i][:,-1])\n",
    "    t = calc_mse_val(p2, b_val[i][:,-1])\n",
    "    print(\"qt = \", qt)\n",
    "    print(\"t = \", t)\n",
    "    print(\"accucracy = \", evaluation(b_val[i], main_tree))\n",
    "    if qt < t:\n",
    "        cmp += 1\n",
    "print(cmp)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "from functools import reduce\n",
    " \n",
    "\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(path, algorithm, *args):\n",
    "    df_bike, b_train, b_val = k_fold(path)\n",
    "    scores = list()\n",
    "    for i in range(len(b_train)):\n",
    "\n",
    "        predicted = algorithm(b_train[i], b_val[i], *args)\n",
    "        actual = b_val[i][:,-1]\n",
    "        mae = calc_mae_val(predicted, actual)\n",
    "        mse = calc_mee_val(predicted, actual)\n",
    "        print(\"mae = \", mae)\n",
    "        print(\"mse = \", mse)\n",
    "        scores.append((mae, mse))\n",
    "    return scores\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "# def test_split(index, value, dataset):\n",
    "#     left, right = list(), list()\n",
    "#     for row in dataset:\n",
    "#         if row[index] < value:\n",
    "#             left.append(row)\n",
    "#         else:\n",
    "#             right.append(row)\n",
    "#     return left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "# def gini_index(groups, classes):\n",
    "#     # count all samples at split point\n",
    "#     n_instances = float(sum([len(group) for group in groups]))\n",
    "#     # sum weighted Gini index for each group\n",
    "#     gini = 0.0\n",
    "#     for group in groups:\n",
    "#         size = float(len(group))\n",
    "#         # avoid divide by zero\n",
    "#         if size == 0:\n",
    "#             continue\n",
    "#         score = 0.0\n",
    "#         # score the group based on the score for each class\n",
    "#         for class_val in classes:\n",
    "#             p = [row[-1] for row in group].count(class_val) / size\n",
    "#             score += p * p\n",
    "#         # weight the group score by its relative size\n",
    "#         gini += (1.0 - score) * (size / n_instances)\n",
    "#     return gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "# def get_split(dataset, n_features):\n",
    "#     class_values = list(set(row[-1] for row in dataset))\n",
    "#     b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "#     features = list()\n",
    "#     while len(features) < n_features:\n",
    "#         index = randrange(len(dataset[0])-1)\n",
    "#         if index not in features:\n",
    "#             features.append(index)\n",
    "#     for index in features:\n",
    "#         for row in dataset:\n",
    "#             groups = test_split(index, row[index], dataset)\n",
    "#             gini = gini_index(groups, class_values)\n",
    "#             if gini < b_score:\n",
    "#                 b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "#     return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "# def to_terminal(group):\n",
    "#     outcomes = [row[-1] for row in group]\n",
    "#     return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# # Create child splits for a node or make terminal\n",
    "# def split(node, max_depth, min_size, n_features, depth):\n",
    "#     left, right = node['groups']\n",
    "#     del(node['groups'])\n",
    "#     # check for a no split\n",
    "#     if not left or not right:\n",
    "#         node['left'] = node['right'] = to_terminal(left + right)\n",
    "#         return\n",
    "#     # check for max depth\n",
    "#     if depth >= max_depth:\n",
    "#         node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "#         return\n",
    "#     # process left child\n",
    "#     if len(left) <= min_size:\n",
    "#         node['left'] = to_terminal(left)\n",
    "#     else:\n",
    "#         node['left'] = get_split(left, n_features)\n",
    "#         split(node['left'], max_depth, min_size, n_features, depth+1)\n",
    "#     # process right child\n",
    "#     if len(right) <= min_size:\n",
    "#         node['right'] = to_terminal(right)\n",
    "#     else:\n",
    "#         node['right'] = get_split(right, n_features)\n",
    "#         split(node['right'], max_depth, min_size, n_features, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "# def build_tree(train, max_depth, min_size, n_features):\n",
    "#     root = get_split(train, n_features)\n",
    "#     split(root, max_depth, min_size, n_features, 1)\n",
    "#     return root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "# def predict(node, row):\n",
    "#     if row[node['index']] < node['value']:\n",
    "#         if isinstance(node['left'], dict):\n",
    "#             return predict(node['left'], row)\n",
    "#         else:\n",
    "#             return node['left']\n",
    "#     else:\n",
    "#         if isinstance(node['right'], dict):\n",
    "#             return predict(node['right'], row)\n",
    "#         else:\n",
    "#             return node['right']\n",
    "\n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample\n",
    "\n",
    "# Make a prediction with a list of bagged trees\n",
    "# return: m x n matrix, m = number of trees, n = number of samples\n",
    "def bagging_predict(trees, val):\n",
    "    predictions = [find_pred(tree, val) for tree in trees]\n",
    "    ##todo: return mean of the column\n",
    "    result = []\n",
    "    for i in range(len(predictions[0])):\n",
    "        retult.append(reduce(lambda x, y : x[i] + y[i], predictions))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Random Forest Algorithm\n",
    "def random_forest(train, test, threshold, sample_size, n_trees, n_features):\n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        tree = regression_tree_helper(sample, n_features, threshold)\n",
    "        trees.append(tree)\n",
    "\n",
    "    return bagging_predict(trees, test)\n",
    "\n",
    "# main_tree = regression_tree_helper(b_train[i], 10)\n",
    "#     p = find_pred(main_tree, b_val[i])\n",
    "#     regressor = DecisionTreeRegressor(random_state=0)\n",
    "#     regressor.fit(b_train[i][:,:-1], b_train[i][:,-1])\n",
    "#     p2 = [x for x in regressor.predict(b_val[i][:,:-1])]\n",
    "#     qt = calc_mse_val(p, b_val[i][:,-1])\n",
    "#     t = calc_mse_val(p2, b_val[i][:,-1])\n",
    "\n",
    "# Test the random forest algorithm\n",
    "seed(2)\n",
    "# load and prepare data\n",
    "# filename = 'sonar.all-data.csv'\n",
    "# dataset = load_csv(filename)\n",
    "# convert string attributes to integers\n",
    "# for i in range(0, len(dataset[0])-1):\n",
    "# str_column_to_float(dataset, i)\n",
    "# # convert class column to integers\n",
    "# str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "regression_tree_helper() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d57c6373e97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_trees\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trees: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scores: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a75ed439f94d>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[0;34m(path, algorithm, *args)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_mae_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a75ed439f94d>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(train, test, threshold, sample_size, n_trees, n_features)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_tree_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: regression_tree_helper() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "path = 'datasets/Bike-Sharing-Dataset/day.csv'\n",
    "threshold = 1\n",
    "sample_size = 1.0\n",
    "n_features = int(sqrt(df.shape[1]-1))\n",
    "for n_trees in [10, 100, 1000]:\n",
    "    scores = evaluate_algorithm(path, random_forest, threshold, sample_size, n_trees, n_features)\n",
    "    print('Trees: %d' % n_trees)\n",
    "    print('Scores: %s' % scores)\n",
    "    print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
